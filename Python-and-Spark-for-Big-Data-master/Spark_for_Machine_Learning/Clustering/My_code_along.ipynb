{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Cluster\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Clustering Code Along.ipynb',\n",
       " 'Clustering_Code_Example.ipynb',\n",
       " 'Clustering_Consulting_Project.ipynb',\n",
       " 'Clustering_Consulting_Project_SOLUTIONS.ipynb',\n",
       " 'hack_data.csv',\n",
       " 'My_code_along.ipynb',\n",
       " 'My_doc_example.ipynb',\n",
       " 'sample_kmeans_data.txt',\n",
       " 'seeds_dataset.csv',\n",
       " 'seeds_dataset.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the data: real experiment at university. They randomly select seeds from 3 different types of wheat and make high resolution xray to get features of selected seeds -> form the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"seeds_dataset.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+\n",
      "| area|perimeter|compactness|  length_of_kernel|   width_of_kernel|asymmetry_coefficient|length_of_groove|\n",
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+\n",
      "|15.26|    14.84|      0.871|             5.763|             3.312|                2.221|            5.22|\n",
      "|14.88|    14.57|     0.8811| 5.553999999999999|             3.333|                1.018|           4.956|\n",
      "|14.29|    14.09|      0.905|             5.291|3.3369999999999997|                2.699|           4.825|\n",
      "|13.84|    13.94|     0.8955|             5.324|3.3789999999999996|                2.259|           4.805|\n",
      "|16.14|    14.99|     0.9034|5.6579999999999995|             3.562|                1.355|           5.175|\n",
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 7\n"
     ]
    }
   ],
   "source": [
    "print(df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- area: double (nullable = true)\n",
      " |-- perimeter: double (nullable = true)\n",
      " |-- compactness: double (nullable = true)\n",
      " |-- length_of_kernel: double (nullable = true)\n",
      " |-- width_of_kernel: double (nullable = true)\n",
      " |-- asymmetry_coefficient: double (nullable = true)\n",
      " |-- length_of_groove: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VecAss = VectorAssembler(inputCols = df.columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = VecAss.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+--------------------+\n",
      "| area|perimeter|compactness|  length_of_kernel|   width_of_kernel|asymmetry_coefficient|length_of_groove|            features|\n",
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+--------------------+\n",
      "|15.26|    14.84|      0.871|             5.763|             3.312|                2.221|            5.22|[15.26,14.84,0.87...|\n",
      "|14.88|    14.57|     0.8811| 5.553999999999999|             3.333|                1.018|           4.956|[14.88,14.57,0.88...|\n",
      "|14.29|    14.09|      0.905|             5.291|3.3369999999999997|                2.699|           4.825|[14.29,14.09,0.90...|\n",
      "|13.84|    13.94|     0.8955|             5.324|3.3789999999999996|                2.259|           4.805|[13.84,13.94,0.89...|\n",
      "|16.14|    14.99|     0.9034|5.6579999999999995|             3.562|                1.355|           5.175|[16.14,14.99,0.90...|\n",
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- area: double (nullable = true)\n",
      " |-- perimeter: double (nullable = true)\n",
      " |-- compactness: double (nullable = true)\n",
      " |-- length_of_kernel: double (nullable = true)\n",
      " |-- width_of_kernel: double (nullable = true)\n",
      " |-- asymmetry_coefficient: double (nullable = true)\n",
      " |-- length_of_groove: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features!!\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scl = StandardScaler(inputCol=\"features\", outputCol=\"scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scl.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+--------------------+--------------------+\n",
      "| area|perimeter|compactness|  length_of_kernel|   width_of_kernel|asymmetry_coefficient|length_of_groove|            features|              scaled|\n",
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+--------------------+--------------------+\n",
      "|15.26|    14.84|      0.871|             5.763|             3.312|                2.221|            5.22|[15.26,14.84,0.87...|[5.24452795332028...|\n",
      "|14.88|    14.57|     0.8811| 5.553999999999999|             3.333|                1.018|           4.956|[14.88,14.57,0.88...|[5.11393027165175...|\n",
      "|14.29|    14.09|      0.905|             5.291|3.3369999999999997|                2.699|           4.825|[14.29,14.09,0.90...|[4.91116018695588...|\n",
      "|13.84|    13.94|     0.8955|             5.324|3.3789999999999996|                2.259|           4.805|[13.84,13.94,0.89...|[4.75650503761158...|\n",
      "|16.14|    14.99|     0.9034|5.6579999999999995|             3.562|                1.355|           5.175|[16.14,14.99,0.90...|[5.54696468981581...|\n",
      "+-----+---------+-----------+------------------+------------------+---------------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(featuresCol=\"scaled\").setK(3).setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = km.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428.6333432285446"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within sum of square error\n",
    "wsse = model.computeCost(scaled_data)\n",
    "wsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 6.35645488, 12.40730852, 37.41990178, 13.93860446,  9.7892399 ,\n",
      "        2.41585013, 12.29286107]), array([ 4.07135818, 10.14438097, 35.86461803, 11.81349589,  7.53471695,\n",
      "        3.18317127, 10.39230304]), array([ 4.94114963, 10.95557919, 37.3028184 , 12.42383591,  8.60815545,\n",
      "        1.80983376, 10.40657797])]\n"
     ]
    }
   ],
   "source": [
    "# get the centers\n",
    "centers = model.clusterCenters()\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred = model.transform(scaled_data).select(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         0|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         1|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
